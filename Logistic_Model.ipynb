{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\spatial\\lib\\site-packages\\rpy2\\robjects\\pandas2ri.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import Index as PandasIndex\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import cascaded_union\n",
    "import numpy as np\n",
    "from fiona.crs import from_epsg\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import rpy2.robjects as ro\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "from rpy2.robjects import Formula\n",
    "pandas2ri.activate()\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import rasterio\n",
    "import glob\n",
    "from pyproj import CRS\n",
    "from fiona.crs import from_epsg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro.r('install.packages(\"dismo\", dependencies=TRUE)')\n",
    "ro.r('install.packages(\"raster\", dependencies=TRUE)')\n",
    "ro.r('install.packages(\"shapefiles\", dependencies=TRUE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shapefiles = importr(\"shapefiles\")\n",
    "dismo = importr(\"dismo\")\n",
    "rgdal = importr(\"rgdal\")\n",
    "raster = importr(\"raster\")\n",
    "base = importr(\"base\")\n",
    "utils = importr(\"utils\")\n",
    "ggplot2 = importr(\"ggplot2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\spatial\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>ISO2</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>UN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>AREA</th>\n",
       "      <th>POP2005</th>\n",
       "      <th>REGION</th>\n",
       "      <th>SUBREGION</th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>df</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AR</td>\n",
       "      <td>AR</td>\n",
       "      <td>ARG</td>\n",
       "      <td>32</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>273669</td>\n",
       "      <td>38747148</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>-65.167</td>\n",
       "      <td>-35.377</td>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((-65.74806 -22.11167, -65.19020 -22.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BL</td>\n",
       "      <td>BO</td>\n",
       "      <td>BOL</td>\n",
       "      <td>68</td>\n",
       "      <td>Bolivia</td>\n",
       "      <td>108438</td>\n",
       "      <td>9182015</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>-64.671</td>\n",
       "      <td>-16.715</td>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((-65.19020 -22.09473, -65.74806 -22.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BR</td>\n",
       "      <td>BR</td>\n",
       "      <td>BRA</td>\n",
       "      <td>76</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>845942</td>\n",
       "      <td>186830759</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>-53.089</td>\n",
       "      <td>-10.772</td>\n",
       "      <td>5</td>\n",
       "      <td>MULTIPOLYGON (((-60.09834 5.21722, -60.14751 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CI</td>\n",
       "      <td>CL</td>\n",
       "      <td>CHL</td>\n",
       "      <td>152</td>\n",
       "      <td>Chile</td>\n",
       "      <td>74880</td>\n",
       "      <td>16295102</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>-69.433</td>\n",
       "      <td>-23.389</td>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((-67.35785 -22.82327, -67.18362 -22.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FG</td>\n",
       "      <td>GF</td>\n",
       "      <td>GUF</td>\n",
       "      <td>254</td>\n",
       "      <td>French Guiana</td>\n",
       "      <td>8815</td>\n",
       "      <td>192099</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>-53.241</td>\n",
       "      <td>3.924</td>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((-52.26559 4.88884, -52.04000 4.33139...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FIPS ISO2 ISO3   UN           NAME    AREA    POP2005  REGION  SUBREGION  \\\n",
       "0   AR   AR  ARG   32      Argentina  273669   38747148      19          5   \n",
       "1   BL   BO  BOL   68        Bolivia  108438    9182015      19          5   \n",
       "2   BR   BR  BRA   76         Brazil  845942  186830759      19          5   \n",
       "3   CI   CL  CHL  152          Chile   74880   16295102      19          5   \n",
       "4   FG   GF  GUF  254  French Guiana    8815     192099      19          5   \n",
       "\n",
       "      LON     LAT  df                                           geometry  \n",
       "0 -65.167 -35.377   5  POLYGON ((-65.74806 -22.11167, -65.19020 -22.0...  \n",
       "1 -64.671 -16.715   5  POLYGON ((-65.19020 -22.09473, -65.74806 -22.1...  \n",
       "2 -53.089 -10.772   5  MULTIPOLYGON (((-60.09834 5.21722, -60.14751 4...  \n",
       "3 -69.433 -23.389   5  POLYGON ((-67.35785 -22.82327, -67.18362 -22.8...  \n",
       "4 -53.241   3.924   5  POLYGON ((-52.26559 4.88884, -52.04000 4.33139...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alty_mcp_polygons=gpd.read_file('alty_mcp_polygon.shp')\n",
    "alty_mcp_polygons.crs=from_epsg(4326)\n",
    "alty_mcp_polygons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\spatial\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>index_righ</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>ISO2</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>UN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>AREA</th>\n",
       "      <th>...</th>\n",
       "      <th>REGION</th>\n",
       "      <th>SUBREGION</th>\n",
       "      <th>LON_1</th>\n",
       "      <th>LAT_1</th>\n",
       "      <th>clust_db</th>\n",
       "      <th>index_ri_1</th>\n",
       "      <th>df_left</th>\n",
       "      <th>index_ri_2</th>\n",
       "      <th>df_right</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alternanthera philoxeroides</td>\n",
       "      <td>172.593303</td>\n",
       "      <td>-43.463020</td>\n",
       "      <td>159</td>\n",
       "      <td>NZ</td>\n",
       "      <td>NZ</td>\n",
       "      <td>NZL</td>\n",
       "      <td>554</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>26799</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>172.235</td>\n",
       "      <td>-42.634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (172.59330 -43.46302)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alternanthera philoxeroides</td>\n",
       "      <td>173.225000</td>\n",
       "      <td>-35.110000</td>\n",
       "      <td>159</td>\n",
       "      <td>NZ</td>\n",
       "      <td>NZ</td>\n",
       "      <td>NZL</td>\n",
       "      <td>554</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>26799</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>172.235</td>\n",
       "      <td>-42.634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (173.22500 -35.11000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alternanthera philoxeroides</td>\n",
       "      <td>174.097125</td>\n",
       "      <td>-35.283900</td>\n",
       "      <td>159</td>\n",
       "      <td>NZ</td>\n",
       "      <td>NZ</td>\n",
       "      <td>NZL</td>\n",
       "      <td>554</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>26799</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>172.235</td>\n",
       "      <td>-42.634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (174.09713 -35.28390)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alternanthera philoxeroides</td>\n",
       "      <td>174.462937</td>\n",
       "      <td>-35.959265</td>\n",
       "      <td>159</td>\n",
       "      <td>NZ</td>\n",
       "      <td>NZ</td>\n",
       "      <td>NZL</td>\n",
       "      <td>554</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>26799</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>172.235</td>\n",
       "      <td>-42.634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (174.46294 -35.95927)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alternanthera philoxeroides</td>\n",
       "      <td>174.716666</td>\n",
       "      <td>-36.783333</td>\n",
       "      <td>159</td>\n",
       "      <td>NZ</td>\n",
       "      <td>NZ</td>\n",
       "      <td>NZL</td>\n",
       "      <td>554</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>26799</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>172.235</td>\n",
       "      <td>-42.634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (174.71667 -36.78333)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       species         lon        lat index_righ FIPS ISO2  \\\n",
       "0  Alternanthera philoxeroides  172.593303 -43.463020        159   NZ   NZ   \n",
       "1  Alternanthera philoxeroides  173.225000 -35.110000        159   NZ   NZ   \n",
       "2  Alternanthera philoxeroides  174.097125 -35.283900        159   NZ   NZ   \n",
       "3  Alternanthera philoxeroides  174.462937 -35.959265        159   NZ   NZ   \n",
       "4  Alternanthera philoxeroides  174.716666 -36.783333        159   NZ   NZ   \n",
       "\n",
       "  ISO3   UN         NAME   AREA  ... REGION SUBREGION    LON_1   LAT_1  \\\n",
       "0  NZL  554  New Zealand  26799  ...      9        53  172.235 -42.634   \n",
       "1  NZL  554  New Zealand  26799  ...      9        53  172.235 -42.634   \n",
       "2  NZL  554  New Zealand  26799  ...      9        53  172.235 -42.634   \n",
       "3  NZL  554  New Zealand  26799  ...      9        53  172.235 -42.634   \n",
       "4  NZL  554  New Zealand  26799  ...      9        53  172.235 -42.634   \n",
       "\n",
       "   clust_db index_ri_1 df_left index_ri_2 df_right  \\\n",
       "0         0          0       0          0        1   \n",
       "1         0          0       0          0        1   \n",
       "2         0          0       0          0        1   \n",
       "3         0          0       0          0        1   \n",
       "4         0          0       0          0        1   \n",
       "\n",
       "                      geometry  \n",
       "0  POINT (172.59330 -43.46302)  \n",
       "1  POINT (173.22500 -35.11000)  \n",
       "2  POINT (174.09713 -35.28390)  \n",
       "3  POINT (174.46294 -35.95927)  \n",
       "4  POINT (174.71667 -36.78333)  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alty_gbif_subsamp=gpd.read_file('alty_gbif_subsamp.shp')\n",
    "alty_gbif_subsamp.crs=from_epsg(4326)\n",
    "alty_gbif_subsamp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(matrix,y_test,p_cap):\n",
    "    a=len(matrix[(matrix.observation==1)&(matrix.model==1)]) #present present\n",
    "    b=len(matrix[(matrix.observation==0)&(matrix.model==1)]) #absent present\n",
    "    c=len(matrix[(matrix.observation==1)&(matrix.model==0)]) #present absent\n",
    "    d=len(matrix[(matrix.observation==0)&(matrix.model==0)]) #absent absent\n",
    "    m=len(matrix)\n",
    "    PCC=(a+d)/m\n",
    "    Kappa=((a+d)-((a+c)*(a+b)+(b+d)*(c+d))/m)/(m-((a+c)*(a+b)+(b+d)*(c+d))/m)\n",
    "    Sensitivity= a/(a+c)\n",
    "    Specificity= d/(b+d)\n",
    "    Precision= a/(a+b)\n",
    "    NPP= d/(c+d)\n",
    "    TSS= (a/(a+c))+(d/(b+d))-1\n",
    "    FPR= b/(b+d)\n",
    "    F_measure= (2*Precision*Sensitivity)/(Precision+Sensitivity)\n",
    "    MCC= (a*d-b*c)/np.sqrt((a+b)*(a+c)*(b+d)*(c+d))\n",
    "    auROC= metrics.roc_auc_score(y_test, p_cap)\n",
    "    Fpr, tpr, thresholds = metrics.roc_curve(y_test, p_cap, pos_label=1)\n",
    "    AUC=metrics.auc(Fpr,tpr)\n",
    "    met=[a,b,c,d,PCC,Kappa,Sensitivity, Specificity, Precision, NPP, TSS, FPR, F_measure, MCC, auROC, AUC]\n",
    "    return(met)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.7592186e+13])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ro.r('memory.limit(size=70000)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic / Logistic L1/ Logistic L2 with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_log =[]; confusion_mat_log =[]; evaluation_mat_log =[];\n",
    "pp =[]; pa =[]; ap =[]; aa =[]; pcc =[]; kappa =[]; sensitivity =[];\n",
    "specificity =[]; precision =[]; npp =[]; tss =[]; fpr =[];\n",
    "fmeasure =[]; mcc =[]; auroc =[]; auc =[];\n",
    "for i in range(100):    \n",
    "    geom_polygons=alty_mcp_polygons['geometry']\n",
    "    geom_union=cascaded_union(geom_polygons)\n",
    "    min_x1, min_y1, max_x1, max_y1=geom_union.bounds\n",
    "    background_points=[]\n",
    "    n=10000\n",
    "    i=0\n",
    "    while i < n:\n",
    "        lons = np.random.uniform(min_x1, max_x1)\n",
    "        lats = np.random.uniform(min_y1, max_y1)\n",
    "        point = Point(lons,lats)\n",
    "        if geom_union.contains(point):\n",
    "            background_points.append(point)\n",
    "            i += 1\n",
    "    lon=[]\n",
    "    lat=[]\n",
    "    for i in range(n):\n",
    "        lon.append(background_points[i].x)\n",
    "        lat.append(background_points[i].y)\n",
    "    data=pd.DataFrame({'lon':lon, 'lat': lat})\n",
    "    len(data)\n",
    "    occurrence_data=pd.DataFrame({'Species':np.repeat(1, len(alty_gbif_subsamp.species)),'lon': alty_gbif_subsamp.lon.values, 'lat': alty_gbif_subsamp.lat.values})\n",
    "    background_data=pd.DataFrame({'Species':np.repeat(0, n), 'lon': lon, 'lat': lat})\n",
    "    final_data=occurrence_data.append(background_data, sort=False)\n",
    "    final_data = final_data.set_index([pd.Index(np.arange(0,len(final_data)))])\n",
    "    geometry=[Point(xy) for xy in zip(final_data.lon, final_data.lat)]\n",
    "    crs = CRS.from_epsg(4326)\n",
    "    Species_data = gpd.GeoDataFrame(final_data, crs=crs, geometry = geometry)\n",
    "    Species_data.to_file('Species_data.shp')\n",
    "    Species_data = gpd.read_file('Species_data.shp')\n",
    "    dir_soil = \"C:/Users/admin/Desktop/Alternanthra philoxeroides/soilgrid0-30/\"\n",
    "    layer_0_5 = [\"bdod_0-5cm_mean\",\"cec_0-5cm_mean\",\"cfvo_0-5cm_mean\",\"clay_0-5cm_mean\",\n",
    "                 \"nitrogen_0-5cm_mean\",\"ocd_0-5cm_mean\",\"phh2o_0-5cm_mean\",\"silt_0-5cm_mean\",\n",
    "                 \"soc_0-5cm_mean\"]\n",
    "    layer_5_15 = [\"bdod_5-15cm_mean\",\"cec_5-15cm_mean\",\"cfvo_5-15cm_mean\",\"clay_5-15cm_mean\",\n",
    "                 \"nitrogen_5-15cm_mean\",\"ocd_5-15cm_mean\",\"phh2o_5-15cm_mean\",\"silt_5-15cm_mean\",\n",
    "                 \"soc_5-15cm_mean\"]\n",
    "    layers = [layer_0_5, layer_5_15]\n",
    "    coords = [(x,y) for x,y in zip(Species_data.lon, Species_data.lat)]\n",
    "    for j in range(len(layers)):\n",
    "        for i in range(len(layers[j])):\n",
    "            src = rasterio.open(dir_soil + layers[j][i] + \".tif\")\n",
    "            Species_data[layers[j][i]] = [x[0] for x in src.sample(coords)]\n",
    "    Species_data.columns=['Species', 'lon', 'lat', 'geometry','SQ11','SQ12','SQ13','SQ14',\n",
    "                  'SQ15','SQ16','SQ17','SQ18',\n",
    "                  'SQ19','SQ21','SQ22','SQ23',\n",
    "                  'SQ24','SQ25','SQ26','SQ27',\n",
    "                  'SQ28','SQ29']\n",
    "    Species_data.to_file('species_soil.shp', index=None)\n",
    "    species_soil = gpd.read_file('species_soil.shp')\n",
    "    shapefiles=importr('shapefiles')\n",
    "    shapes=shapefiles.read_dbf(\"species_soil.dbf\")\n",
    "    data2=pd.DataFrame()\n",
    "    data2['1']=np.repeat(1,len(species_soil.Species))\n",
    "    data2[['lon','lat']]=species_soil[['lon','lat']]\n",
    "    data2[['SQ11','SQ12','SQ13','SQ14',\n",
    "                  'SQ15','SQ16','SQ17','SQ18',\n",
    "                  'SQ19','SQ21','SQ22','SQ23',\n",
    "                  'SQ24','SQ25','SQ26','SQ27',\n",
    "                  'SQ28','SQ29']] = species_soil[['SQ11','SQ12','SQ13','SQ14','SQ15','SQ16','SQ17','SQ18',\n",
    "                                                  'SQ19','SQ21','SQ22','SQ23','SQ24','SQ25','SQ26','SQ27','SQ28','SQ29']]\n",
    "    data2['0']=np.repeat(0,len(species_soil.Species))\n",
    "    sp=importr('sp')\n",
    "    geodata=sp.SpatialPointsDataFrame(coords = data2[['lon','lat']], data = data2, proj4string = sp.CRS(\"+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0\"))\n",
    "    geodata\n",
    "    raster=importr('raster')\n",
    "    bioclim_data_=raster.getData(name=\"worldclim\", download=True, var=\"bio\", res=2.5, path=\"D:/Alien\")\n",
    "    #bioclim_data_=raster.getData(name=\"CMIP5\", download=True, var=\"bio\", res=2.5, rcp=26, model=\"GS\", year=50, path=\"E:/r\")\n",
    "\n",
    "    bioclim_data=raster.extract(bioclim_data_, geodata, method=\"bilinear\")\n",
    "    bio=ro.pandas2ri.ri2py(bioclim_data)\n",
    "    #name=\"worldclim\", download=TRUE, var=\"bio\", res=2.5, path=\"E:/r\"\n",
    "    bioclim=pd.DataFrame(bio, columns=['bio1','bio2','bio3','bio4','bio5','bio6','bio7','bio8','bio9','bio10','bio11','bio12','bio13','bio14','bio15','bio16','bio17','bio18','bio19'])\n",
    "    bioclim.to_csv('bioclimgs_data.csv', index=None)\n",
    "    bioclim=pd.read_csv('bioclimgs_data.csv')#bioclim['Species']=Species_data.Species.values\n",
    "    bioclim[['Species', 'lon', 'lat', 'SQ11','SQ12','SQ13','SQ14',\n",
    "              'SQ15','SQ16','SQ17','SQ18',\n",
    "              'SQ19','SQ21','SQ22','SQ23',\n",
    "              'SQ24','SQ25','SQ26','SQ27',\n",
    "              'SQ28','SQ29']]=species_soil[['Species', 'lon', 'lat', 'SQ11','SQ12','SQ13','SQ14',\n",
    "              'SQ15','SQ16','SQ17','SQ18',\n",
    "              'SQ19','SQ21','SQ22','SQ23',\n",
    "              'SQ24','SQ25','SQ26','SQ27',\n",
    "              'SQ28','SQ29']]\n",
    "    #bioclim=bioclim.drop(labels='Unnamed: 0', axis=1)\n",
    "    bioclim.head()\n",
    "    alty_clim=gpd.GeoDataFrame(bioclim, crs=species_soil.crs, geometry=species_soil.geometry)\n",
    "    alty_clim=alty_clim[['Species', 'lon', 'lat', 'bio1', 'bio2', 'bio3', 'bio4', 'bio5', 'bio6', 'bio7', 'bio8', 'bio9',\n",
    "           'bio10', 'bio11', 'bio12', 'bio13', 'bio14', 'bio15', 'bio16', 'bio17',\n",
    "           'bio18', 'bio19', 'geometry','SQ11','SQ12','SQ13','SQ14',\n",
    "                  'SQ15','SQ16','SQ17','SQ18',\n",
    "                  'SQ19','SQ21','SQ22','SQ23',\n",
    "                  'SQ24','SQ25','SQ26','SQ27',\n",
    "                  'SQ28','SQ29']]\n",
    "    alty_clim=alty_clim.dropna(axis=0)\n",
    "    alty_clim.head()\n",
    "\n",
    "    data=alty_clim\n",
    "    data_n=data.drop(['lon','lat','geometry'], axis=1)\n",
    "    X=data[['bio1', 'bio2', 'bio3', 'bio4', 'bio5', 'bio6', 'bio7', 'bio8', 'bio9', 'bio10', \n",
    "            'bio11', 'bio12', 'bio13', 'bio14', 'bio15', 'bio16', 'bio17','bio18', 'bio19',\n",
    "            'SQ11','SQ12','SQ13','SQ14',\n",
    "                  'SQ15','SQ16','SQ17','SQ18',\n",
    "                  'SQ19','SQ21','SQ22','SQ23',\n",
    "                  'SQ24','SQ25','SQ26','SQ27',\n",
    "                  'SQ28','SQ29']]\n",
    "    y=data[['Species']]\n",
    "\n",
    "    X=X.values\n",
    "    y=y.values\n",
    "    y=np.ravel(y.transpose())\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    \n",
    "    '''\n",
    "    logistic = LogisticRegression()\n",
    "    penalty=['none']\n",
    "    solver=['newton-cg', 'saga', 'sag', 'lbfgs']\n",
    "    C=np.logspace(-4,4,10)\n",
    "    hyperparameters=dict(C=C, penalty=penalty, solver=solver)\n",
    "    asf=GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "    clf=asf.fit(X_train, y_train)\n",
    "    '''\n",
    "    logistic = LogisticRegression()\n",
    "    penalty=['l1']\n",
    "    solver=['liblinear', 'saga']\n",
    "    C=np.logspace(-4,4,10)\n",
    "    hyperparameters=dict(C=C, penalty=penalty, solver=solver)\n",
    "    asf=GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "    clf=asf.fit(X_train, y_train)\n",
    "    '''\n",
    "    logistic = LogisticRegression()\n",
    "    penalty=['l2']\n",
    "    solver=['liblinear', 'saga', 'sag', 'lbfgs', 'newton-cg']\n",
    "    C=np.logspace(-4,4,10)\n",
    "    hyperparameters=dict(C=C, penalty=penalty, solver=solver)\n",
    "    asf=GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "    clf=asf.fit(X_train, y_train)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    p_cap=clf.best_estimator_.predict_proba(X_test)\n",
    "    accur=sum(y)/len(y)\n",
    "    accuracy_log.append(accur)\n",
    "    model=np.zeros(len(X_test))\n",
    "    for i in range(len(X_test)):\n",
    "        if(p_cap[i,1]>=accur):\n",
    "            model[i]=1\n",
    "        else:\n",
    "            model[i]=0\n",
    "    #matrix= pd.DataFrame({'observation': data['Species'].values, 'predicted prob': p_cap[:,0], 'model': clf.predict(X)})\n",
    "    matrix= pd.DataFrame({'observation': y_test, 'predicted prob': p_cap[:,1], 'model': model})\n",
    "    [a,b,c,d,PCC,Kappa,Sensitivity,Specificity,Precision,NPP, TSS,FPR,F_measure,MCC,auROC,AUC]=metric(matrix,y_test,p_cap[:,1])\n",
    "    pp.append(a); ap.append(b);pa.append(c);aa.append(d)\n",
    "    #print(a,b,c,d)\n",
    "    #condusion matrix\n",
    "    conf_mat=pd.DataFrame({'predicted v /observed >': ['Present', 'Absent'], 'Present': [a,c], 'Absent':[b,d]})\n",
    "    conf_mat.set_index('predicted v /observed >')\n",
    "    confusion_mat_log.append(conf_mat)\n",
    "    pcc.append(PCC); kappa.append(Kappa); sensitivity.append(Sensitivity); specificity.append(Specificity); \n",
    "    precision.append(Precision); npp.append(NPP); tss.append(TSS); fpr.append(FPR); fmeasure.append(F_measure); mcc.append(MCC); \n",
    "    auroc.append(auROC); auc.append(AUC)\n",
    "    #auROC is area under reciever operating curve\n",
    "    modl_eval=[PCC, Kappa, Sensitivity, Specificity, Precision, NPP, TSS, FPR, F_measure, MCC, auROC, AUC]    \n",
    "    modl_name=['PCC', 'Kappa', 'Sensitivity', 'Specificity', 'Precision(or PPP)', 'NPP', 'TSS', 'FPR', 'F measure', 'MCC', 'auROC', 'AUC']\n",
    "    modl_expln=['Percent correctly identified', 'Difference between prediction accuracy and chance agreement', 'Proportion of observed presence correctly predicted', 'Proportion of observed absence correctly predicted', 'proportion of predicted presence correctly predicted', 'proportion of observed presence correctly predicted', 'True skill statistic', 'False positive rate(1 - Specificity)','','Matthews correlation coefficient', 'Area under receiver operating curve', 'Threshold Independent']\n",
    "    #modl_eval=[r'$\\frac{a+d}{n}=$', r'$\\frac{(\\(a+d\\)-\\frac{(\\(a+c\\)\\(a+b\\)+\\(b+d\\)\\(c+d\\))}{n})}{n-\\frac{\\(a+\\c)\\(a+\\b)+\\(b+d\\)\\(c+d\\)}{n}}$', r'$\\frac{a}{a+c}$',r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$']\n",
    "    evalu=pd.DataFrame({'model name': modl_name, ' Explanation': modl_expln, 'Evaluation': modl_eval})\n",
    "    evaluation_mat_log.append(evalu)\n",
    "\n",
    "log_data=pd.DataFrame({'accuracy':accuracy_log, 'present/present':pp, 'present/absent':pa, 'absent/present':ap,'absent/absent': aa, 'pcc':pcc,'kappa':kappa,'sensitivity':sensitivity,'specificity':specificity,'precision':precision,'npp':npp,'tss':tss,'fpr':fpr,'fmeasure':fmeasure,'mcc':mcc,'auroc':auroc,'auc':auc})\n",
    "log_data.to_csv('logl1s_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic / Logistic L1/ Logistic L2 without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_log =[]; confusion_mat_log =[]; evaluation_mat_log =[];\n",
    "pp =[]; pa =[]; ap =[]; aa =[]; pcc =[]; kappa =[]; sensitivity =[];\n",
    "specificity =[]; precision =[]; npp =[]; tss =[]; fpr =[];\n",
    "fmeasure =[]; mcc =[]; auroc =[]; auc =[];\n",
    "for i in range(100):    \n",
    "    geom_polygons=alty_mcp_polygons['geometry']\n",
    "    geom_union=cascaded_union(geom_polygons)\n",
    "    min_x1, min_y1, max_x1, max_y1=geom_union.bounds\n",
    "    background_points=[]\n",
    "    n=10000\n",
    "    i=0\n",
    "    while i < n:\n",
    "        lons = np.random.uniform(min_x1, max_x1)\n",
    "        lats = np.random.uniform(min_y1, max_y1)\n",
    "        point = Point(lons,lats)\n",
    "        if geom_union.contains(point):\n",
    "            background_points.append(point)\n",
    "            i += 1\n",
    "    lon=[]\n",
    "    lat=[]\n",
    "    for i in range(n):\n",
    "        lon.append(background_points[i].x)\n",
    "        lat.append(background_points[i].y)\n",
    "    data=pd.DataFrame({'lon':lon, 'lat': lat})\n",
    "    len(data)\n",
    "    occurrence_data=pd.DataFrame({'Species':np.repeat(1, len(alty_gbif_subsamp.species)),'lon': alty_gbif_subsamp.lon.values, 'lat': alty_gbif_subsamp.lat.values})\n",
    "    background_data=pd.DataFrame({'Species':np.repeat(0, n), 'lon': lon, 'lat': lat})\n",
    "    final_data=occurrence_data.append(background_data, sort=False)\n",
    "    final_data = final_data.set_index([pd.Index(np.arange(0,len(final_data)))])\n",
    "    geometry=[Point(xy) for xy in zip(final_data.lon, final_data.lat)]\n",
    "    crs = CRS.from_epsg(4326)\n",
    "    Species_data = gpd.GeoDataFrame(final_data, crs=crs, geometry = geometry)\n",
    "    Species_data.to_file('Species_data.shp')\n",
    "    Species_data = gpd.read_file('Species_data.shp')\n",
    "    dir_soil = \"C:/Users/admin/Desktop/Alternanthra philoxeroides/soilgrid0-30/\"\n",
    "    layer_0_5 = [\"bdod_0-5cm_mean\",\"cec_0-5cm_mean\",\"cfvo_0-5cm_mean\",\"clay_0-5cm_mean\",\n",
    "                 \"nitrogen_0-5cm_mean\",\"ocd_0-5cm_mean\",\"phh2o_0-5cm_mean\",\"silt_0-5cm_mean\",\n",
    "                 \"soc_0-5cm_mean\"]\n",
    "    layer_5_15 = [\"bdod_5-15cm_mean\",\"cec_5-15cm_mean\",\"cfvo_5-15cm_mean\",\"clay_5-15cm_mean\",\n",
    "                 \"nitrogen_5-15cm_mean\",\"ocd_5-15cm_mean\",\"phh2o_5-15cm_mean\",\"silt_5-15cm_mean\",\n",
    "                 \"soc_5-15cm_mean\"]\n",
    "    layers = [layer_0_5, layer_5_15]\n",
    "    coords = [(x,y) for x,y in zip(Species_data.lon, Species_data.lat)]\n",
    "    for j in range(len(layers)):\n",
    "        for i in range(len(layers[j])):\n",
    "            src = rasterio.open(dir_soil + layers[j][i] + \".tif\")\n",
    "            Species_data[layers[j][i]] = [x[0] for x in src.sample(coords)]\n",
    "    Species_data.columns=['Species', 'lon', 'lat', 'geometry','SQ11','SQ12','SQ13','SQ14',\n",
    "                  'SQ15','SQ16','SQ17','SQ18',\n",
    "                  'SQ19','SQ21','SQ22','SQ23',\n",
    "                  'SQ24','SQ25','SQ26','SQ27',\n",
    "                  'SQ28','SQ29']\n",
    "    Species_data.to_file('species_soil.shp', index=None)\n",
    "    species_soil = gpd.read_file('species_soil.shp')\n",
    "    shapefiles=importr('shapefiles')\n",
    "    shapes=shapefiles.read_dbf(\"species_soil.dbf\")\n",
    "    data2=pd.DataFrame()\n",
    "    data2['1']=np.repeat(1,len(species_soil.Species))\n",
    "    data2[['lon','lat']]=species_soil[['lon','lat']]\n",
    "    data2[['SQ11','SQ12','SQ13','SQ14',\n",
    "                  'SQ15','SQ16','SQ17','SQ18',\n",
    "                  'SQ19','SQ21','SQ22','SQ23',\n",
    "                  'SQ24','SQ25','SQ26','SQ27',\n",
    "                  'SQ28','SQ29']] = species_soil[['SQ11','SQ12','SQ13','SQ14','SQ15','SQ16','SQ17','SQ18',\n",
    "                                                  'SQ19','SQ21','SQ22','SQ23','SQ24','SQ25','SQ26','SQ27','SQ28','SQ29']]\n",
    "    data2['0']=np.repeat(0,len(species_soil.Species))\n",
    "    sp=importr('sp')\n",
    "    geodata=sp.SpatialPointsDataFrame(coords = data2[['lon','lat']], data = data2, proj4string = sp.CRS(\"+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0\"))\n",
    "    geodata\n",
    "    raster=importr('raster')\n",
    "    bioclim_data_=raster.getData(name=\"worldclim\", download=True, var=\"bio\", res=2.5, path=\"D:/Alien\")\n",
    "    #bioclim_data_=raster.getData(name=\"CMIP5\", download=True, var=\"bio\", res=2.5, rcp=26, model=\"GS\", year=50, path=\"E:/r\")\n",
    "\n",
    "    bioclim_data=raster.extract(bioclim_data_, geodata, method=\"bilinear\")\n",
    "    bio=ro.pandas2ri.ri2py(bioclim_data)\n",
    "    #name=\"worldclim\", download=TRUE, var=\"bio\", res=2.5, path=\"E:/r\"\n",
    "    bioclim=pd.DataFrame(bio, columns=['bio1','bio2','bio3','bio4','bio5','bio6','bio7','bio8','bio9','bio10','bio11','bio12','bio13','bio14','bio15','bio16','bio17','bio18','bio19'])\n",
    "    bioclim.to_csv('bioclimgs_data.csv', index=None)\n",
    "    bioclim=pd.read_csv('bioclimgs_data.csv')#bioclim['Species']=Species_data.Species.values\n",
    "    bioclim[['Species', 'lon', 'lat', 'SQ11','SQ12','SQ13','SQ14',\n",
    "              'SQ15','SQ16','SQ17','SQ18',\n",
    "              'SQ19','SQ21','SQ22','SQ23',\n",
    "              'SQ24','SQ25','SQ26','SQ27',\n",
    "              'SQ28','SQ29']]=species_soil[['Species', 'lon', 'lat', 'SQ11','SQ12','SQ13','SQ14',\n",
    "              'SQ15','SQ16','SQ17','SQ18',\n",
    "              'SQ19','SQ21','SQ22','SQ23',\n",
    "              'SQ24','SQ25','SQ26','SQ27',\n",
    "              'SQ28','SQ29']]\n",
    "    #bioclim=bioclim.drop(labels='Unnamed: 0', axis=1)\n",
    "    bioclim.head()\n",
    "    alty_clim=gpd.GeoDataFrame(bioclim, crs=species_soil.crs, geometry=species_soil.geometry)\n",
    "    alty_clim=alty_clim[['Species', 'lon', 'lat', 'bio1', 'bio2', 'bio3', 'bio4', 'bio5', 'bio6', 'bio7', 'bio8', 'bio9',\n",
    "           'bio10', 'bio11', 'bio12', 'bio13', 'bio14', 'bio15', 'bio16', 'bio17',\n",
    "           'bio18', 'bio19', 'geometry','SQ11','SQ12','SQ13','SQ14',\n",
    "                  'SQ15','SQ16','SQ17','SQ18',\n",
    "                  'SQ19','SQ21','SQ22','SQ23',\n",
    "                  'SQ24','SQ25','SQ26','SQ27',\n",
    "                  'SQ28','SQ29']]\n",
    "    alty_clim=alty_clim.dropna(axis=0)\n",
    "    alty_clim.head()\n",
    "\n",
    "    data=alty_clim\n",
    "    data_n=data.drop(['lon','lat','geometry'], axis=1)\n",
    "    X=data[['bio1', 'bio2', 'bio3', 'bio4', 'bio5', 'bio6', 'bio7', 'bio8', 'bio9', 'bio10', \n",
    "            'bio11', 'bio12', 'bio13', 'bio14', 'bio15', 'bio16', 'bio17','bio18', 'bio19',\n",
    "            'SQ11','SQ12','SQ13','SQ14',\n",
    "                  'SQ15','SQ16','SQ17','SQ18',\n",
    "                  'SQ19','SQ21','SQ22','SQ23',\n",
    "                  'SQ24','SQ25','SQ26','SQ27',\n",
    "                  'SQ28','SQ29']]\n",
    "    y=data[['Species']]\n",
    "\n",
    "    X=X.values\n",
    "    y=y.values\n",
    "    y=np.ravel(y.transpose())\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "    \n",
    "    '''\n",
    "    logistic = LogisticRegression()\n",
    "    penalty=['none']\n",
    "    solver=['newton-cg', 'saga', 'sag', 'lbfgs']\n",
    "    C=np.logspace(-4,4,10)\n",
    "    hyperparameters=dict(C=C, penalty=penalty, solver=solver)\n",
    "    asf=GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "    clf=asf.fit(X_train, y_train)\n",
    "    '''\n",
    "    logistic = LogisticRegression()\n",
    "    penalty=['l1']\n",
    "    solver=['liblinear', 'saga']\n",
    "    C=np.logspace(-4,4,10)\n",
    "    hyperparameters=dict(C=C, penalty=penalty, solver=solver)\n",
    "    asf=GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "    clf=asf.fit(X_train, y_train)\n",
    "    '''\n",
    "    logistic = LogisticRegression()\n",
    "    penalty=['l2']\n",
    "    solver=['liblinear', 'saga', 'sag', 'lbfgs', 'newton-cg']\n",
    "    C=np.logspace(-4,4,10)\n",
    "    hyperparameters=dict(C=C, penalty=penalty, solver=solver)\n",
    "    asf=GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "    clf=asf.fit(X_train, y_train)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    p_cap=clf.best_estimator_.predict_proba(X_test)\n",
    "    accur=sum(y)/len(y)\n",
    "    accuracy_log.append(accur)\n",
    "    model=np.zeros(len(X_test))\n",
    "    for i in range(len(X_test)):\n",
    "        if(p_cap[i,1]>=accur):\n",
    "            model[i]=1\n",
    "        else:\n",
    "            model[i]=0\n",
    "    #matrix= pd.DataFrame({'observation': data['Species'].values, 'predicted prob': p_cap[:,0], 'model': clf.predict(X)})\n",
    "    matrix= pd.DataFrame({'observation': y_test, 'predicted prob': p_cap[:,1], 'model': model})\n",
    "    [a,b,c,d,PCC,Kappa,Sensitivity,Specificity,Precision,NPP, TSS,FPR,F_measure,MCC,auROC,AUC]=metric(matrix,y_test,p_cap[:,1])\n",
    "    pp.append(a); ap.append(b);pa.append(c);aa.append(d)\n",
    "    #print(a,b,c,d)\n",
    "    #condusion matrix\n",
    "    conf_mat=pd.DataFrame({'predicted v /observed >': ['Present', 'Absent'], 'Present': [a,c], 'Absent':[b,d]})\n",
    "    conf_mat.set_index('predicted v /observed >')\n",
    "    confusion_mat_log.append(conf_mat)\n",
    "    pcc.append(PCC); kappa.append(Kappa); sensitivity.append(Sensitivity); specificity.append(Specificity); \n",
    "    precision.append(Precision); npp.append(NPP); tss.append(TSS); fpr.append(FPR); fmeasure.append(F_measure); mcc.append(MCC); \n",
    "    auroc.append(auROC); auc.append(AUC)\n",
    "    #auROC is area under reciever operating curve\n",
    "    modl_eval=[PCC, Kappa, Sensitivity, Specificity, Precision, NPP, TSS, FPR, F_measure, MCC, auROC, AUC]    \n",
    "    modl_name=['PCC', 'Kappa', 'Sensitivity', 'Specificity', 'Precision(or PPP)', 'NPP', 'TSS', 'FPR', 'F measure', 'MCC', 'auROC', 'AUC']\n",
    "    modl_expln=['Percent correctly identified', 'Difference between prediction accuracy and chance agreement', 'Proportion of observed presence correctly predicted', 'Proportion of observed absence correctly predicted', 'proportion of predicted presence correctly predicted', 'proportion of observed presence correctly predicted', 'True skill statistic', 'False positive rate(1 - Specificity)','','Matthews correlation coefficient', 'Area under receiver operating curve', 'Threshold Independent']\n",
    "    #modl_eval=[r'$\\frac{a+d}{n}=$', r'$\\frac{(\\(a+d\\)-\\frac{(\\(a+c\\)\\(a+b\\)+\\(b+d\\)\\(c+d\\))}{n})}{n-\\frac{\\(a+\\c)\\(a+\\b)+\\(b+d\\)\\(c+d\\)}{n}}$', r'$\\frac{a}{a+c}$',r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$', r'$\\frac{3}{4} \\binom{3}{4} \\stackrel{3}{4}$']\n",
    "    evalu=pd.DataFrame({'model name': modl_name, ' Explanation': modl_expln, 'Evaluation': modl_eval})\n",
    "    evaluation_mat_log.append(evalu)\n",
    "\n",
    "log_data=pd.DataFrame({'accuracy':accuracy_log, 'present/present':pp, 'present/absent':pa, 'absent/present':ap,'absent/absent': aa, 'pcc':pcc,'kappa':kappa,'sensitivity':sensitivity,'specificity':specificity,'precision':precision,'npp':npp,'tss':tss,'fpr':fpr,'fmeasure':fmeasure,'mcc':mcc,'auroc':auroc,'auc':auc})\n",
    "log_data.to_csv('logl1_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
